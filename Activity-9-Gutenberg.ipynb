{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeeb3719",
   "metadata": {},
   "source": [
    "## Activity 9: Extraction the top 100 ebooks from Gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407d7a6",
   "metadata": {},
   "source": [
    "## Import the necessary libraries, including regex and beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61e62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51dc345",
   "metadata": {},
   "source": [
    "## Check the SSL certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00383a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I willl use the sssl default_context and the use the check_hostname to \n",
    "# check the SSL certificate\n",
    "SSL_certificate = ssl.create_default_context()\n",
    "SSL_certificate.check_hostname = False\n",
    "SSL_certificate.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90391c2",
   "metadata": {},
   "source": [
    "## Read the HTML from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e3bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the requests.get to read the HTML from the URL which will allow us to pass\n",
    "# the url to BeautifulSoup\n",
    "Gutenberg = 'https://www.gutenberg.org/browse/scores/top'\n",
    "response = requests.get(Gutenberg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fbf5eb",
   "metadata": {},
   "source": [
    "## Write a small function to check the status of web request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "006b4cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web request status complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next I will define my function to check the status of the web request through the use of\n",
    "# status code set to 200 and printing out a response if the web request worked.\n",
    "def web_request_status(req_stat):\n",
    "    if req_stat.status_code==200:\n",
    "        print(\"Web request status complete\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Status lost\")\n",
    "        return -1\n",
    "web_request_status(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f791736e",
   "metadata": {},
   "source": [
    "## Decode the response and pass this on to BeautifulSoup for HTML parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8540f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the repsonse and cotent to decode and pass the decoded response to beautifulsoup\n",
    "# that will be used to parse the HTML\n",
    "decode_response = response.content.decode(response.encoding)\n",
    "soup_pass = BeautifulSoup(decode_response, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba71521",
   "metadata": {},
   "source": [
    "## Find all the href tags and store them in the list of links. Check how the list looks like - print first 30 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b7d1161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/about/',\n",
       " '/about/',\n",
       " '/policy/collection_development.html',\n",
       " '/about/contact_information.html',\n",
       " '/about/background/',\n",
       " '/policy/permission.html',\n",
       " '/policy/privacy_policy.html',\n",
       " '/policy/terms_of_use.html',\n",
       " '/ebooks/',\n",
       " '/ebooks/',\n",
       " '/ebooks/bookshelf/',\n",
       " '/browse/scores/top',\n",
       " '/ebooks/offline_catalogs.html',\n",
       " '/help/',\n",
       " '/help/',\n",
       " '/help/copyright.html',\n",
       " '/help/errata.html',\n",
       " '/help/file_formats.html',\n",
       " '/help/faq.html',\n",
       " '/policy/',\n",
       " '/help/public_domain_ebook_submission.html',\n",
       " '/help/submitting_your_own_work.html',\n",
       " '/help/mobile.html',\n",
       " '/attic/',\n",
       " '/donate/',\n",
       " '/donate/',\n",
       " '#books-last1',\n",
       " '#authors-last1',\n",
       " '#books-last7']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First I will create an empty list that will hold the http links that are from \n",
    "# the HTML page. Then I will find the href tags and store them in my empty list I created \n",
    "# and then print the list out through the use of append and link get. \n",
    "tags_list=[]\n",
    "for link in soup_pass.find_all('a'):\n",
    "    tags_list.append(link.get('href'))\n",
    "tags_list[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3299c0fd",
   "metadata": {},
   "source": [
    "## Use regular expression to find the numeric digits in these links. These are the file numbers for the Top 100 eBooks. Initialize the empty list to hold the file numbers over an appropriate range and use regex to find the numeric digits in the link href string. Use the findall method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b74ae568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66616, 98, 43, 1661, 64317, 844, 219, 1232, 1260, 408, 46, 205, 2591, 66618, 23811, 23, 66613, 76, 160, 1250, 1727, 2814, 66612, 2554, 66617, 4980, 3207, 55, 6130, 16328, 66619, 4300, 5740, 2148, 996, 7370, 74, 16, 120, 2852, 514, 45, 1400, 3825, 203, 2600, 779, 768, 209, 1184, 215, 10007, 19942, 140, 58585, 35, 1497, 158, 15399, 3600, 1429, 36, 42884, 20203, 32449, 4517, 135, 1597, 829, 30254, 11030, 63256, 28054, 3296, 1998, 113, 2500, 902, 43453, 730, 22381, 1934, 61, 147, 4363, 244, 1524, 1251, 1, 1, 7, 7, 30, 30, 61, 37, 68, 111, 28, 53]\n"
     ]
    }
   ],
   "source": [
    "# First I will create an empty list for the file numbers and then create a for statement \n",
    "# to find the range for the numeric digits. While using a Regular expression which will \n",
    "# be used to find the numeric digits then through the use of append we can cast the \n",
    "# number into a integer\n",
    "file_numbers=[]\n",
    "for i in range(45,145):\n",
    "    link=tags_list[i]\n",
    "    link=link.strip()\n",
    "    n=re.findall('[0-9]+',link)\n",
    "    if len(n)==1:\n",
    "        file_numbers.append(int(n[0]))\n",
    "print(file_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a4fbe",
   "metadata": {},
   "source": [
    "## What does the soup object's text look like? Use .text method and print only the first 2,000 characters (i.e. do not print the whole thing, it is long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58a5e582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 100 | Project Gutenberg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menu▾\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "          ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "About Project Gutenberg\n",
      "Collection Development\n",
      "Contact Us\n",
      "History & Philosophy\n",
      "Permissions & License\n",
      "Privacy Policy\n",
      "Terms of Use\n",
      "\n",
      "\n",
      "\n",
      "Search and Browse\n",
      "      \t  ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "Book Search\n",
      "Bookshelves\n",
      "Frequently Downloaded\n",
      "Offline Catalogs\n",
      "\n",
      "\n",
      "\n",
      "Help\n",
      "          ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "All help topics →\n",
      "Copyright Procedures\n",
      "Errata, Fixes and Bug Reports\n",
      "File Formats\n",
      "Frequently Asked Questions\n",
      "Policies →\n",
      "Public Domain eBook Submission\n",
      "Submitting Your Own Work\n",
      "Tablets, Phones and eReaders\n",
      "The Attic →\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Frequently Viewed or Downloaded\n",
      "These listings are based on the number of times each eBook gets downloaded.\n",
      "      Multiple downloads from the same Internet address on the same day count as one download, and addresses that download more than 100 eBooks in a day are considered robots and are not counted.\n",
      "\n",
      "Downloaded Books\n",
      "2021-10-27181609\n",
      "last 7 days1168311\n",
      "last 30 days4888843\n",
      "\n",
      "\n",
      "\n",
      "Top 100 EBooks yesterday\n",
      "Top 100 Authors yesterday\n",
      "Top 100 EBooks last 7 days\n",
      "Top 100 Authors last 7 days\n",
      "Top 100 EBooks last 30 days\n",
      "Top 100 Authors last 30 days\n",
      "\n",
      "\n",
      "Top 100 EBooks yesterday\n",
      "\n",
      "Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley (3692)\n",
      "Pride and Prejudice by Jane Austen (2112)\n",
      "The Scarlet Letter by Nathaniel Hawthorne (1503)\n",
      "The Legend of Sleepy Hollow by Washington Irving (1201)\n",
      "Dracula by Bram Stoker (1043)\n",
      "Alice's Adventures in Wonderland by Lewis Carroll (1033)\n",
      "A Doll's House : a play by Henrik Ibsen (916)\n",
      "A Modest Proposal by Jonathan Swift (853)\n",
      "Moby Dick; Or, The Whale by Herman Melville (829)\n",
      "The Picture of Dorian Gray by Oscar Wilde (819)\n",
      "Metamorphosis by Franz Kafka (818)\n",
      "The Yellow Wallpaper by Charlotte Perkins Gilman (812)\n",
      "Elementary Course in Woodwork by George Alexander Ross (746)\n",
      "A Tale of Two Cities by Charles Dickens (742)\n",
      "The Strange Case of Dr. Jekyll and Mr. Hyde by Robert Louis Stevenson (740)\n",
      "The Adventures of Sherlock Holmes by Arthur Conan Doyle (735\n"
     ]
    }
   ],
   "source": [
    "# Next I will use the print function to prin the first 2,000 characters\n",
    "print(soup_pass.text[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c1f452",
   "metadata": {},
   "source": [
    "## Search in the extracted text (using a regular expression) from the soup object to find the names of the top 100 eBooks (Yesterday's ranking). Create a starting index. It should point at the text Top 100 Ebooks yesterday. Use the splitlines method of the soup.text. It splits the lines of  text of the soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e06a84b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I will create another empty list that will be used to hold the book names. Then \n",
    "# I will use the split lines and index to to point at the text of the top 100 Ebooks.\n",
    "Ebook_names=[]\n",
    "Index_Ebook=soup_pass.text.splitlines().index('Top 100 EBooks yesterday')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc4e1f",
   "metadata": {},
   "source": [
    "## Loop 1-100 to add the strings of the next 100 lines to this temporary list. Hint: use the splitlines method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3d4bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next I will use a for statemet to loop 1-100 to add the strings through the use of the\n",
    "# splitlines method.\n",
    "for i in range(100):\n",
    "    Ebook_names.append(soup_pass.text.splitlines()[Index_Ebook+2+i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef53a99",
   "metadata": {},
   "source": [
    "## Use a regular expression to extract only text from the name strings and append it to an empty list. Use match and span to find the indices and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "970303b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next I will create an empty list to store my titles then use a for statement to find the \n",
    "# range of 100 to extract the text from the name strings. Then use match to find the indices.\n",
    "Updated_Ebook_names=[]\n",
    "for i in range(100):\n",
    "    id1,id2=re.match('^[a-zA-Z ]*',Ebook_names[i]).span()\n",
    "    Updated_Ebook_names.append(Ebook_names[i][id1:id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "263fe3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top \n",
      "Top \n",
      "Top \n",
      "Top \n",
      "\n",
      "\n",
      "Top \n",
      "\n",
      "Frankenstein\n",
      "Pride and Prejudice by Jane Austen \n",
      "The Scarlet Letter by Nathaniel Hawthorne \n",
      "The Legend of Sleepy Hollow by Washington Irving \n",
      "Dracula by Bram Stoker \n",
      "Alice\n",
      "A Doll\n",
      "A Modest Proposal by Jonathan Swift \n",
      "Moby Dick\n",
      "The Picture of Dorian Gray by Oscar Wilde \n",
      "Metamorphosis by Franz Kafka \n",
      "The Yellow Wallpaper by Charlotte Perkins Gilman \n",
      "Elementary Course in Woodwork by George Alexander Ross \n",
      "A Tale of Two Cities by Charles Dickens \n",
      "The Strange Case of Dr\n",
      "The Adventures of Sherlock Holmes by Arthur Conan Doyle \n",
      "The Great Gatsby by F\n",
      "The Importance of Being Earnest\n",
      "Heart of Darkness by Joseph Conrad \n",
      "The Prince by Niccol\n",
      "Jane Eyre\n",
      "The Souls of Black Folk by W\n",
      "A Christmas Carol in Prose\n",
      "Walden\n",
      "Grimms\n",
      "The Pioneer by Irving E\n",
      "The Good Ship Rover by Robina F\n",
      "Narrative of the Life of Frederick Douglass\n",
      "The Last Plunge by Samuel J\n",
      "Adventures of Huckleberry Finn by Mark Twain \n",
      "The Awakening\n",
      "Anthem by Ayn Rand \n",
      "The Odyssey by Homer \n",
      "Dubliners by James Joyce \n",
      "Wanted\n",
      "Crime and Punishment by Fyodor Dostoyevsky \n",
      "Lord Alistair\n",
      "Old Granny Fox by Thornton W\n",
      "Leviathan by Thomas Hobbes \n",
      "The Wonderful Wizard of Oz by L\n",
      "The Iliad by Homer \n",
      "Beowulf\n",
      "The Oxford Book of English Verse\n",
      "Ulysses by James Joyce \n",
      "Tractatus Logico\n",
      "The Works of Edgar Allan Poe \n",
      "Don Quixote by Miguel de Cervantes Saavedra \n",
      "Second Treatise of Government by John Locke \n",
      "The Adventures of Tom Sawyer\n",
      "Peter Pan by J\n",
      "Treasure Island by Robert Louis Stevenson \n",
      "The Hound of the Baskervilles by Arthur Conan Doyle \n",
      "Little Women by Louisa May Alcott \n",
      "Anne of Green Gables by L\n",
      "Great Expectations by Charles Dickens \n",
      "Pygmalion by Bernard Shaw \n",
      "Uncle Tom\n",
      "War and Peace by graf Leo Tolstoy \n",
      "The Tragical History of Doctor Faustus by Christopher Marlowe \n",
      "Wuthering Heights by Emily Bront\n",
      "The Turn of the Screw by Henry James \n",
      "The Count of Monte Cristo\n",
      "The Call of the Wild by Jack London \n",
      "Carmilla by Joseph Sheridan Le Fanu \n",
      "Candide by Voltaire \n",
      "The Jungle by Upton Sinclair \n",
      "The Prophet by Kahlil Gibran \n",
      "The Time Machine by H\n",
      "The Republic by Plato \n",
      "Emma by Jane Austen \n",
      "The Interesting Narrative of the Life of Olaudah Equiano\n",
      "Essays of Michel de Montaigne \n",
      "The Garden Party\n",
      "The War of the Worlds by H\n",
      "The Philippine Islands\n",
      "Autobiography of Benjamin Franklin by Benjamin Franklin \n",
      "Japanese Girls and Women by Alice Mabel Bacon \n",
      "Ethan Frome by Edith Wharton \n",
      "Les Mis\n",
      "Andersen\n",
      "Gulliver\n",
      "The Romance of Lust\n",
      "Incidents in the Life of a Slave Girl\n",
      "The American Diary of a Japanese Girl by Yon\n",
      "The Brothers Karamazov by Fyodor Dostoyevsky \n",
      "The Confessions of St\n",
      "Thus Spake Zarathustra\n",
      "The Secret Garden by Frances Hodgson Burnett \n",
      "Siddhartha by Hermann Hesse \n",
      "The Happy Prince\n",
      "A Pickle for the Knowing Ones by Timothy Dexter \n",
      "Oliver Twist by Charles Dickens \n"
     ]
    }
   ],
   "source": [
    "# Last I will use tha for statement to print the list of ebook names.\n",
    "for Ebook_names in Updated_Ebook_names:\n",
    "    print(Ebook_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19faea1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
